{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum number of posts we can get per minute is 1200.0\n",
      "The maximum number of posts we can get per day is 1728000.0\n"
     ]
    }
   ],
   "source": [
    "# Max number of requests\n",
    "max_requests = 60/5\n",
    "items_per_request = 100\n",
    "max_posts = max_requests * items_per_request\n",
    "print(\"The maximum number of posts we can get per minute is\", max_posts)\n",
    "print(\"The maximum number of posts we can get per day is\", max_posts * 24 * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort = 'relevance'  # 'relevance', 'hot', 'top', 'new', 'comments'\n",
    "t = 'all'  # all, day, hour, month, week, year\n",
    "\n",
    "def search_reddit(query, limit):\n",
    "    base_url = 'https://www.reddit.com/search.json'\n",
    "    headers = {'User-agent': 'yourbot'}\n",
    "    posts = []\n",
    "    params = {\n",
    "        'q': query,\n",
    "        'limit': 100,  # Reddit API returns max 100 posts per request\n",
    "        'after': None,\n",
    "        'sort': sort,\n",
    "        't': t\n",
    "            }\n",
    "    while len(posts) < limit:\n",
    "        try:\n",
    "            response = requests.get(base_url, headers=headers, params=params)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "\n",
    "            new_posts = data['data']['children']\n",
    "            if not new_posts:\n",
    "                print('No more posts found.')\n",
    "                break\n",
    "            posts.extend(new_posts)\n",
    "            after = data['data']['after']\n",
    "            if after is None:\n",
    "                print('No more posts to fetch.')\n",
    "                break\n",
    "            \n",
    "            # Print progress\n",
    "            print(f'Retrieved {len(posts)} posts so far...')\n",
    "            \n",
    "            # Sleep to avoid hitting rate limits (50 calls per minute -> 1.2 seconds per call)\n",
    "            time.sleep(5)\n",
    "        except requests.exceptions.HTTPError as err:\n",
    "            print(f'HTTP error occurred: {err}')\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f'An Error Occurred: {e}')\n",
    "            break\n",
    "\n",
    "    return posts[:limit]\n",
    "\n",
    "def convert_timestamp_to_date(posts):\n",
    "    for post in posts:\n",
    "        timestamp = post['data']['created_utc']\n",
    "        date = datetime.fromtimestamp(timestamp, tz=timezone.utc).strftime('%Y/%m/%d')\n",
    "        post['data']['created_date'] = date\n",
    "    return posts\n",
    "\n",
    "# export to Excel\n",
    "def get_post_data(posts):\n",
    "    data = []\n",
    "    for post in posts:\n",
    "        x = post['data']\n",
    "        data.append([x['title'], x['selftext'], x[\"author_fullname\"], x['url'], x['created_date'], x['num_comments'], x['score']])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 100 posts so far...\n",
      "Retrieved 200 posts so far...\n",
      "Retrieved 300 posts so far...\n",
      "Retrieved 400 posts so far...\n",
      "Retrieved 500 posts so far...\n",
      "Retrieved 600 posts so far...\n",
      "Retrieved 700 posts so far...\n",
      "Retrieved 800 posts so far...\n",
      "Retrieved 900 posts so far...\n",
      "Retrieved 1000 posts so far...\n",
      "Retrieved 1100 posts so far...\n",
      "Retrieved 1200 posts so far...\n",
      "Retrieved 1300 posts so far...\n",
      "Retrieved 1400 posts so far...\n",
      "Retrieved 1500 posts so far...\n",
      "Retrieved 1600 posts so far...\n",
      "Retrieved 1700 posts so far...\n",
      "Retrieved 1800 posts so far...\n",
      "Retrieved 1900 posts so far...\n",
      "Retrieved 2000 posts so far...\n",
      "Retrieved 2000 posts\n",
      "Retrieved 100 posts so far...\n",
      "Retrieved 200 posts so far...\n",
      "Retrieved 300 posts so far...\n",
      "Retrieved 400 posts so far...\n",
      "Retrieved 500 posts so far...\n",
      "Retrieved 600 posts so far...\n",
      "Retrieved 700 posts so far...\n",
      "Retrieved 800 posts so far...\n",
      "Retrieved 900 posts so far...\n",
      "Retrieved 1000 posts so far...\n",
      "Retrieved 1100 posts so far...\n",
      "Retrieved 1200 posts so far...\n",
      "Retrieved 1300 posts so far...\n",
      "Retrieved 1400 posts so far...\n",
      "Retrieved 1500 posts so far...\n",
      "Retrieved 1600 posts so far...\n",
      "Retrieved 1700 posts so far...\n",
      "Retrieved 1800 posts so far...\n",
      "Retrieved 1900 posts so far...\n",
      "Retrieved 2000 posts so far...\n",
      "Retrieved 2000 posts\n",
      "Retrieved 100 posts so far...\n",
      "Retrieved 200 posts so far...\n",
      "Retrieved 300 posts so far...\n",
      "Retrieved 400 posts so far...\n",
      "Retrieved 500 posts so far...\n",
      "Retrieved 600 posts so far...\n",
      "Retrieved 700 posts so far...\n",
      "Retrieved 800 posts so far...\n",
      "Retrieved 900 posts so far...\n",
      "Retrieved 1000 posts so far...\n",
      "Retrieved 1100 posts so far...\n",
      "Retrieved 1200 posts so far...\n",
      "Retrieved 1300 posts so far...\n",
      "Retrieved 1400 posts so far...\n",
      "Retrieved 1500 posts so far...\n",
      "Retrieved 1600 posts so far...\n",
      "Retrieved 1700 posts so far...\n",
      "Retrieved 1800 posts so far...\n",
      "Retrieved 1900 posts so far...\n",
      "Retrieved 2000 posts so far...\n",
      "Retrieved 2000 posts\n"
     ]
    }
   ],
   "source": [
    "for subreddit in [\"antiwork\", \"jobs\", \"careerguidance\"]:\n",
    "    query = f'(ai OR chatgpt OR \"artificial intelligence\") subreddit:{subreddit}'\n",
    "    limit = 2000\n",
    "\n",
    "    posts = search_reddit(query, limit)\n",
    "    posts = convert_timestamp_to_date(posts)\n",
    "\n",
    "    print(f\"Retrieved {len(posts)} posts\")\n",
    "\n",
    "    data = get_post_data(posts)\n",
    "\n",
    "    export_query = query.replace(\":\", \"_\").replace('\"', ' ') + f\" sort_{sort} t_{t}\"\n",
    "    pd.DataFrame(data).to_excel(f'../data/{export_query}.xlsx', header=['Title', 'Body', 'Author', 'URL', 'Created', 'Comments', 'Score'], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
